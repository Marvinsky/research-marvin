%% abtex2-modelo-include-comandos.tex, v-1.9.5 laurocesar
%% Copyright 2012-2015 by abnTeX2 group at http://www.abntex.net.br/ 
%%
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%   http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2005/12/01 or later.
%%
%% This work has the LPPL maintenance status `maintained'.
%% 
%% The Current Maintainer of this work is the abnTeX2 team, led
%% by Lauro César Araujo. Further information are available on 
%% http://www.abntex.net.br/
%%
%% This work consists of the files abntex2-modelo-include-comandos.tex
%% and abntex2-modelo-img-marca.pdf
%%

% ---
% Este capítulo, utilizado por diferentes exemplos do abnTeX2, ilustra o uso de
% comandos do abnTeX2 e de LaTeX.
% ---

\externaldocument[I-]{chapter03}

\chapter{Empirical Evaluation}\label{ch:empirical_evaluation}
\noindent
The practical effectiveness of \texttt{GHS} depends on its ability of finding good approximations $\hat{J}$ and $\hat{T}$. In order to verify its practical effectiveness, we have implemented \texttt{GHS} in Fast Downward (Helmert, \citeyear{helmert2006fast}) and tested the A$\sp{*}$ performance using subsets of heuristics selected by \texttt{GHS} while minimizing different objective funcions.

We run two sets of experiments. In the first set we verify whether the approximations $\hat{J}$ and $\hat{T}$ provided by \texttt{CS} and \texttt{SS} allow \texttt{GHS} selects good subset selections for A$\sp{*}$ search tree size and running time. In the second set of experiments we test the effectiveness of \texttt{GHS} by measuring the total number of problem instances solved by A$\sp{*}$ using a heuristic subset selected by \texttt{GHS}.

\texttt{GHS} is executed up to adding another heuristic does not improve the objective function. In each iteration \texttt{GHS} greedily selects from $\zeta$ the heuristic $h$ which will result in the largest reduction of the value of the objective function $\Psi$. We can't control the size of the resulting subset because \texttt{GHS} stops if adding another heuristic $h$ to the $\zeta\sp{'}$ does not improve the objective function and returns the current subset $\zeta\sp{'}$.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
\centering
\caption{Ratios of the number of nodes generated using $h_{max}(\zeta\sp{'})$ to the number of nodes generated using $h_{max}(\zeta)$}
\begin{tabular}{lrrrrrr}
\hline
\multirow{2}{*}{Domain} & \multicolumn{2}{c}{\texttt{SS}} & \multicolumn{2}{c}{\texttt{CS}}   & \multirow{2}{*}{|$\zeta$|} & \multirow{2}{*}{n} \\ \cline{2-5}
                        & Ratio    & |$\zeta\sp{'}$|   & Ratio  & |$\zeta\sp{'}$| &                            &                    \\ \hline
Barman                  & 1.11     & 17.70       & 1.50   & 30.25           & 5168.50                    & 20                 \\
Elevators               & 11.50     & 2.00       & 1.03   & 21.00           & 168.00                     & 1                  \\
Floortile               & 1.02     & 43.07       & 1.01   & 42.35           & 151.28                     & 14                 \\
Openstacks              & 1.00     & 1.00        & 1.00   & 1.00            & 390.69                     & 13                 \\
Parking                 & 1.00     & 5.52        & 1.01   & 7.26            & 21.73                      & 19                 \\
Pegsol                  & 1.00     & 31.00       & 1.00   & 57.00           & 90.00                      & 2                  \\
Scanalyzer              & 1.22     & 30.57       & 1.56   & 19.42           & 72.85                      & 7                  \\
Tidybot                 & 1.00     & 2.35        & 1.00   & 8.58            & 3400.17                    & 17                 \\
Transport               & 1.00     & 14.70        & 1.02   & 14.30           & 171.7                     & 10                  \\
Visitall                & 1.02     & 99.33       & 1.18   & 48.66           & 256.33                     & 3                  \\
Woodworking             & 32.42     & 3.00       & 199.65 & 5.00           & 1289.00                     & 5                  \\ \hline
\end{tabular}
\label{tb_one}
\end{table}

\iffalse
In all our experiments we use a type system that assigned the same type for a node with the same $f-$value. Such a type system has shown to be effective in guiding \texttt{SS} to produce accurate tree size predictions in other application domains Lelis et al., (\citeyear{lelis2013predicting}), Lelis et al., (\citeyear{lelis2014memory}).
\fi

We ran our experiments on the 2011 International Planning Competition (\texttt{IPC}) instances. We used the 2011 instances instead of the 2014 instances because the former do not have problems with conditional effects, which are currently not handled by \textbf{PDB} heuristics. All experiments are run on $2.67$ GHz machines with 4GB, and are limited to 1,800 seconds of running time.

% ---
\section{Empirical Evaluation of $\hat{J}$ and $\hat{T}$}
\noindent
% ---
We test whether the approximation $\hat{J}$ provided by \texttt{CS} and \texttt{SS} allows \texttt{GHS} to make good subset selections. This test is made by comparing $J(\zeta\sp{'})$ with $J(\zeta)$, which is minimal. The condition $J(\zeta\sp{'}) \leq \alpha \cdot J(\zeta)$, is sufficient to show that $J(\zeta\sp{'})$ is within $\alpha$ times good with respect to all subsets of any size, for some constant $\alpha$. 

In contrast with objective function $J$, there is no easy way to find the minimum of $T$ for a subset in general. We experiment then with the special case in which all heuristics in $\zeta$ have the same evaluation time. This way we are able to test whether the estimates $\hat{T}$ are allowing \texttt{GHS} to make good subset selections while minimizing the A$\sp{*}$ running time. This is because by only selecting heuristics which have the same evaluation time, if \texttt{GHS} is making good subset selections with respect to $J$, then \texttt{GHS}, also must be making good subset selections with respect to $T$.

We collect values of $J(\zeta)$ and $J(\zeta\sp{'})$ as follows. For each problem instance $\nabla$ in our test set we generate a set of \texttt{PDB} heuristics using the \texttt{GA-PDB} algorithm Edelkamp, (\citeyear{edelkamp2007automated}) as described by Barley et al., (\citeyear{BarleySantiagoOver}) $-$ we call each \texttt{PDB} generated by this method a \texttt{GA-PDB}. We chose to use \texttt{GA-PDBs} in this experiment because they all have nearly the same evaluation time and will allow us to verify whether \texttt{GHS} is making good selections when minimizing $J$ and $T$, as explained above. The number of \texttt{GA-PDBs} generated is limited in this experiment by 1,200 seconds and 1GB of memory. Also, all \texttt{GA-PDBs} we generate have 2 millions entries each. The \texttt{GA-PDBs} generated form our $\zeta$ set. \texttt{GHS} then selects a subset $\zeta\sp{'}$ of $\zeta$. Finally, we use $h_{max}(\zeta\sp{'})$ and $h_{max}(\zeta)$ to independently try to solve $\nabla$. We call the system which uses A$\sp{*}$ with $h_{max}(\zeta)$ the \texttt{Max} approach. For \texttt{GHS} we allow 600 seconds for selecting $\zeta\sp{'}$ and for running A$\sp{*}$ with $h_{max}(\zeta\sp{'})$, and for \texttt{Max} we allow 600 seconds for running A$\sp{*}$ with $h_{max}(\zeta)$. Since we used 1,200 seconds to generate the heuristics, both \texttt{Max} and \texttt{GHS} were allowed 1,800 seconds in total for solving each problem. In this experiment we test both \texttt{CS} and \texttt{SS}.

In this experiment we refer to the approach that runs A$\sp{*}$ guided by a heuristic subset selected by \texttt{GHS} using \texttt{CS} as \texttt{GHS+CS}. Similarly, we write \texttt{GHS+SS} when \texttt{SS} is used as predictor to make the heuristic subset selection.

Table \ref{tb_one} shows the average ratios of $J(\zeta\sp{'})$ to $J(\zeta)$ for both \texttt{SS} and \texttt{CS} in different problem domains. The value of $J$, for a given problem instance, is computed as the number of nodes expanded up to the largest $f$-layer which is fully expanded by all approaches tested (\texttt{Max, GHS} using \texttt{SS} and \texttt{GHS} using \texttt{CS}). We only present results for instances that are not solved during \texttt{GHS}'s \texttt{CS} sampling process. The column ``$n$'' shows the number of instances used to compute the averages of each row. We also show the average number of \texttt{GA-PDBs} generated (|$\zeta$|) and the average number of \texttt{GA-PDBs} selected by \texttt{GHS} (|$\zeta\sp{'}$|). This experiment shows that for most of the problems \texttt{GHS}, using \texttt{CS} or \texttt{SS}, is selecting good subset of $\zeta$ for A$\sp{*}$ search tree size and running time. For example, in Tidybot \texttt{GHS} selects only a few \texttt{GA-PDBs} out of thousands when using either \texttt{SS} or \texttt{CS}.

The exceptions in Table \ref{tb_one} are the ratios for Elevators, Scanalyzer and Woodworking. In Elevators \texttt{SS} has an average ratio of $11.50$ and \texttt{CS} of $1.03$. By looking at the ratios of \texttt{SS} for individual instances of Scanalyzer (results now show in Table \ref{tb_one}), we noticed that \texttt{SS} is able to make good selections for all but 3 of the 7 instances considered in this experiment. Since we do not know a priori what is the instance's optimal solution cost, \texttt{SS} samples nodes with $f-$values much larger than the instance's optimal solution cost. We believe that, in this particular instance of Scanalyzer, by sampling a portion of the state space that is not expanded during the actual A$\sp{*}$, \texttt{SS} is biasing the subset selection to select heuristics that do not contribute to reducing the actual A$\sp{*}$ search tree size.

\begin{table}[]
\centering
\caption{Coverage of \texttt{SS}, \texttt{CS} and \texttt{Max} on the 2011 IPC benchmarks. For GHS using only \texttt{GA-PDBs} heuristics.}
\label{my-label}
\begin{tabular}{lccc}
\hline
Domain      & SS & CS & Max \\ \hline
Barman      & 8          & 7          & 4           \\
Elevators   & 19         & 19         & 19          \\
Floortile   & 10         & 10         & 9           \\
Nomystery   & 20         & 20         & 20          \\
Openstacks  & 17         & 17         & 11          \\
Parcprinter & 17         & 15         & 14          \\
Parking     & 1          & 1          & 1           \\
Pegsol      & 19         & 19         & 19          \\
Scanalyzer  & 10         & 10         & 10          \\
Sokoban     & 20         & 20         & 20          \\
Tidybot     & 14         & 13         & 11          \\
Transport   & 14         & 14         & 14          \\
Visitall    & 18         & 18         & 18          \\
Woodworking & 12         & 11         & 12          \\ \hline
Total       & 199        & 194        & 182         \\ \hline
\end{tabular}
\label{tb_onlygapdbs}
\end{table}


The \texttt{SS}'s ability of sampling deep into the search space is not always harmful. For example, \texttt{SS} allows \texttt{GHS} to make good selections for instances of the Woodworking domain. By contrast, \texttt{CS}'s systematic approach to sampling only allow a shallow sample of the A$\sp{*}$ search tree. As a result, \texttt{GHS} makes a limited selection of heuristics to guide A$\sp{*}$ search. While \texttt{GHS} using \texttt{SS} selects an average of 3 heuristics in Woodworking instances, \texttt{GHS} using \texttt{CS} selects only an average of 5 heuristics. This difference on sampling strategies reflects on the number of problems solved by A$\sp{*}$. While \texttt{GHS+SS} solves 12 instances of the Woodworking domain, \texttt{GHS+CS} solves only 11. In total, out of the 280 instances of the \texttt{IPC} 2011 benchmark set, \texttt{GHS+SS} solves 199 problem instances in this experiment, while \texttt{GHS+CS} only solves 194 problem instances. (The numbers of instances solved are shown in Table \ref{tb_onlygapdbs}).

\section{Comparison with Other Planning Systems}
\noindent
The objective of this second set of experiments is to test the quality of the subset of heuristics \texttt{GHS} selects while optimizing different objective functions. Our evaluation metric is coverage, i.e., number of problems solved within a 1,800 second time limit. We note that the 1,800-second limit includes the time to generate $\zeta$, select $\zeta\sp{'}$, and run A$\sp{*}$ using $h_{max}(\zeta\sp{'})$. The $\zeta$ set of heuristics is composed of a number of different \texttt{GA-PDBs}, a \texttt{PDB} heuristic produced by the \texttt{iPDB} method Haslum et al., (\citeyear{haslum2007domain}) and the \texttt{LM-Cut} heuristic. The generation of \texttt{GA-PDBs} is limited by 600 seconds and 1GB of memory. We use one fourth of 600 seconds to genetate \texttt{GA-PDBs} with each of the following number of entries: $\{2 \cdot 10\sp{3}, 2 \cdot 10\sp{4}, 2 \cdot 10\sp{5}, 2 \cdot 10\sp{6}\}$. Our approach allows one to generate up to thousands of \texttt{GA-PDBs}. For every problem instance, we use exactly the same $\zeta$ set for \texttt{Max} and all \texttt{GHS} approaches.

\section{Systems Tested}
\noindent
\texttt{GHS} is tested while minimizing the A$\sp{*}$ search tree size (\texttt{Size}) and the A$\sp{*}$ running time (\texttt{Time}). We also use \texttt{GHS} to maximize the sum of heuristic values in the state space (\texttt{Sum}), as suggested by Rayner et al., (\citeyear{raynersss13}). Rayner et al., (\citeyear{raynersss13}) assumed that one could uniformly sample states in the state space in order to estimte the sum of the heuristic values for a given heuristic subset. Since we are not aware of any method to uniformly sample the state space of domain-independent problems, we adapted the Rayner et al., (\citeyear{raynersss13})'s method by using \texttt{SS} to estimate the sum of heuristic values in the search tree rooted at $\nabla$'s start state. We write \texttt{Size+SS} to refer to the approach that used A$\sp{*}$ guided by a heuristic selected by \texttt{GHS} while minimizing an estimate of the search tree size provided by \texttt{SS}. We follow the same pattern to name the other possible combinations of objective functions and prediction algorithms (e.g., \texttt{Time}+\texttt{CS}).

In addition to experimenting with all combinations of prediction algorithms (\texttt{CS} and \texttt{SS}) and objective functions (\texttt{Time}, \texttt{Size}), we also experiment with an approach that minimizes both the search tree size and the running time as follows. First we create a pool of heuristics $\zeta$ composed solely of \texttt{GA-PDB} heuristics, then we apply \texttt{GHS} while minimizing tree size and using \texttt{SS} as predictor. We call the selection of a subset of \texttt{GA-PDBs} as the \textit{first selection}. Once the first selection is made, we test all possible combinations of the resulting $h_{max}(\zeta\sp{'})$ added to \texttt{iPDB} and \texttt{LM-Cut} heuristics while minimizing the running time as estimated by \texttt{CS}$-$we call this step the \textit{second selection}. We call the overall approach \texttt{Hybrid}.
%As explained above, in this setting \texttt{GHS} minimizes $J$ and $T$ simultaneaously, as all heuristics in $\zeta$ have the same evaluation time (Theorem \ref{th:theorem_evaluation_time_heuristic})

The intuition behind \texttt{Hibrid} is that we apply \texttt{GHS} with its strongest settings. \texttt{GHS} makes good selections respect to $J$ and $T$ when selecting from a pool of heuristics with the same evaluation time. After such a selection is made, we reduce the size of the pool of heuristics from possible thousands to only three (the maximum of a subset of the initial \texttt{GA-PDBs, iPDB}, and \texttt{LM-Cut}). With only three heuristics we are able to choose the exact combination that minimizes the A$\sp{*}$ running time the most. The reason we chose to use \texttt{SS} instead of \texttt{CS} for the first selection in \texttt{Hybrid} is that the former is able to make better subset selections in this setting, as suggested by the results discussed in the previous Chapter \ref{ch:rghs}. Finally, as we show below, \texttt{CS} is more effective if one is interested in minimizing the A$\sp{*}$ running time while selecting from a pool of heuristic with different evaluation times. That is why we use \texttt{CS} as predictor for the second selection in \texttt{Hybrid}.

We compare the coverage of the \texttt{GHS} approaches with several other state-of-the-art planners. Namely, we experiment with RIDA$\sp{*}$ Barley et al., (\citeyear{BarleySantiagoOver}), two variants of StoneSoup (StSp1 and StSp2) as described by Nissim et al., (\citeyear{nissim2011computing}), two versions of Symba (SY1 and SY2) (Torralba, \citeyear{torralba2015phd}), and A$\sp{*}$ being independently guided by the maximum of all heuristics in $\zeta$ (\texttt{Max}), \texttt{iPDB, LM-cut} and \texttt{Merge $\&$ Shrink}(\texttt{M$\&$S}) Nissim et al., (\citeyear{nissim2011computing}). The results are presented in Table \ref{tb_two}.

\section{Discussion of the Results}
\noindent
The system that solves the largest number of instances is \texttt{Hybrid}$-$ it solves 219 problems on average. As explained above, we combine in \texttt{Hybrid} the strengths of both \texttt{SS} and \texttt{CS} in a single system. \texttt{GHS} uses \texttt{SS} to select heuristics from a pool of heuristics with similar evaluation time, and only then \texttt{CS} is used for selecting heuristics with different evaluation times. This strategy has proven particularly effective on the Barman domain where \texttt{Hybrid}'s first selection is able to select good subsets of \texttt{GA-PDBs} and its second selection is able to recognize that it must not include the \texttt{iPDB} and \texttt{LM-Cut} heuristics to the subset selected by its first selection. As a result, \texttt{Hybrid} solves more problems on this domain than any other \texttt{GHS} approach.

\texttt{Time}+\texttt{CS} also performed well in our experiments$-$the approach solves 216 problems on average. Clearly \texttt{Hybrid} and \texttt{Time}+\texttt{CS} are far superior to all other approaches tested. For example, \texttt{Size+SS} and \texttt{Sum} solves only 206 and 207 problems, respectively. While minimizing the search tree size or maximizing the sum of heuristic values, \texttt{GHS} will tend to add accurate heuristics to the selected subset, independently of their evaluation time. As a result, if not minimizing the running time, \texttt{GHS} often adds the \texttt{LM-Cut} heuristic to $\zeta\sp{'}$ as \texttt{LM-Cut} is often the heuristic that is able to reduce the most the search tree size and to increase the most the sum of heuristic values. However, \texttt{LM-Cut} is very computationally expensive, and in various cases the search is faster if \texttt{LM-Cut} is not in $\zeta\sp{'}$. Both \texttt{Hybrid} and \texttt{Time}+\texttt{CS} are able to recognize when \texttt{LM-Cut} should not be included in $\zeta\sp{'}$ because they account for the heuristics' evaluation time.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[htb]
\footnotesize\setlength{\tabcolsep}{1.8pt}
\centering
\caption{Coverage of different planning systems on the 2011 \texttt{IPC} benchmarks. For the \texttt{GHS} and \texttt{Max} approaches we also present the average number of heuristics \texttt{GHS} selects (|$\zeta\sp{'}$|).}
\begin{tabular}{lrrrrrrrrrrrrrrr}
\hline
\multirow{2}{*}{Domains} & 
\multirow{2}{*}{\texttt{Hybrid}} & 
\multicolumn{2}{c}{\texttt{CS}} & 
\multicolumn{2}{c}{\texttt{SS}} & 
\multirow{2}{*}{\texttt{Sum}} & 
\multirow{2}{*}{\texttt{Max}} &
\multirow{2}{*}{RIDA$\sp{*}$} & 
\multirow{2}{*}{SY1} & 
\multirow{2}{*}{SY2} & 
\multirow{2}{*}{StSp1} & 
\multirow{2}{*}{StSp2} & 
\multirow{2}{*}{iPDB} & 
\multirow{2}{*}{LM-Cut} & 
\multirow{2}{*}{M$\&$S} \\ \cline{3-6}
                         &                                    & \texttt{Time} & \texttt{Size} & \texttt{Time} & \texttt{Size} &                                 &                       &                      &                      &                        &                        &                                 &                       &                         &                         \\ \hline
Barman&         7&      5&     4&    4&    4&    4&   4&    4&    10&  11&    4&    4&    4&     4&   4\\
Elevators&     19&     19&    19&   19&   19&   19&  19&   19&    20&  20&   18&   18&   18&    17&  12\\
Floortile&     15&     14&    14&   14&   14&   14&  14&   14&    14&  14&   14&   14&   14&     8&  10\\
Nomystery&     20&     20&    20&   19&   19&   20&  20&   20&    16&  16&   20&   20&   14&    19&  18\\
Openstacks&    17&     17&    15&   17&   15&   15&  11&   15&    20&  20&   17&   17&   15&    17&  17\\
Parcprinter&   18&     18&    18&   16&   15&   19&  18&   18&    17&  17&   18&   18&   17&    16&  16\\
Parking&        7&      7&     2&    7&    2&    2&   2&    7&     2&   1&    5&    5&    2&     7&   7\\
Pegsol&        18&     18&    19&   19&   19&   19&  19&   19&    19&  20&   19&   19&   17&    20&  19\\
Scanalyzer&    13&     14&    12&   11&   14&   14&  14&   14&     9&   9&   14&   14&   12&    10&  11\\
Sokoban&       20&     20&    20&   20&   20&   20&  20&   20&    20&  20&   20&   20&   20&    20&  20\\
Tidybot&       17&     16&    16&   16&   16&   16&  15&   17&    15&  17&   16&   16&   16&    14&   9\\
Transport&     14&     13&    10&   11&   13&   11&   9&   10&    10&  11&    7&    8&    6&     8&   7\\
Visitall&      18&     18&    18&   15&   18&   18&  18&   18&    12&  12&   16&   16&   10&    16&  16\\
Woodworking&   16&     15&    15&   12&   16&   16&  16&   15&    20&  20&   15&   15&   15&     9&   9\\ \hline
Total&        219&    214&   202&  200&  204&  207& 199&  210&   204& 208&  203&  204&  180&   185& 175\\ \hline
\end{tabular}
\label{tb_two}
\end{table}

Note that the difference on the number of problems solved by \texttt{Time}+\texttt{CS} and \texttt{Time}+\texttt{SS}: While the former solves 214 instances, the latter solved only 200. We conjecture that this happens because \texttt{SS} is not able to detect duplicated nodes during sampling. As a result, \texttt{SS} often overestimates by several orders of magnitude the actual A$\sp{*}$'s running time. Similarly to the \texttt{Size} and \texttt{Sum} approaches, due to \texttt{SS}'s overestimations, \texttt{Time}+\texttt{SS} often mistakenly adds the accurate but expensive \texttt{LM-Cut} heuristic in cases where the A$\sp{*}$ search would be faster without \texttt{LM-Cut}'s guidence. 
\iffalse
For example, although \texttt{iPDB} tends to prune fewer nodes than \texttt{LM-Cut} in Woodworking instances, \texttt{iPDB} is the heuristic of choice in that domain. This is because its evaluation time is much smaller than \texttt{LM-Cut}'s. \texttt{Time}+\texttt{CS} solves 7 Parking instances on average as it correctly selects \texttt{iPDB} and leaves \texttt{LM-Cut} out of $\zeta\sp{'}$. By contrast, likely due to its prediction overestimation, \texttt{Time}+\texttt{SS} solves 7 parking instances because wrongly estimates \texttt{LM-Cut} that will reduce overall search time and adds the heuristic to its selected subset. Notice, that \texttt{Size+CS} and \texttt{Size+SS} also do poorly Parking instances as they also always select \texttt{LM-Cut}.
\fi

RIDA$\sp{*}$ is the most similar system to \texttt{GHS}, as it also selects a subset of heuristics from a pool of heuristics by using an evaluation method similar to \texttt{CS}. RIDA$\sp{*}$ uses a systematic approach for selecting a subset of heuristics. Namely, it starts with an empty subset and evaluates all subsets of size $i$ before evaluating subsets of size $i+1$. This procedure allows RIDA$\sp{*}$ to consider only tens of heuristics in their pool. By contrast, \texttt{GHS} is able to consider thousands of heuristics while making its selection.

The ability to handle large set of heuristics can be helpful, even if most of the heuristics in the set are redundant with each other$-$as is the case with the \texttt{GA-PDBs}. The process of generating \texttt{GA-PDBs} is stochastic, thus one increases the chances of generating helpful heuristic by generating a large number of them. \texttt{GHS} is an effective method for selecting a small set of informative heuristics from a large set of mostly uninformative ones. This is illustrated in Table \ref{tb_two} on the Transport domain. Compared to systems which use multiple heuristics (StSp1 and 2, and RIDA$\sp{*}$), \texttt{Time}+\texttt{CS} solves the largest number of Transport instances, which is due to the selection of a few key \texttt{GA-PDBs}.

The best \texttt{GHS} approach, \texttt{Hybrid}, substantially outperforms the number of instances solved by \texttt{Max}; \texttt{Hybrid} solves on average more than 20 instances than \texttt{Max}. Finally, \texttt{Hybrid} and \texttt{Time}+\texttt{CS} substantially outperforms all other approaches tested, with RIDA$\sp{*}$ being the closest competitor with 210 instances solved.

\clearpage