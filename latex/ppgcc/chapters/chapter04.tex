%% abtex2-modelo-include-comandos.tex, v-1.9.5 laurocesar
%% Copyright 2012-2015 by abnTeX2 group at http://www.abntex.net.br/ 
%%
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%   http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2005/12/01 or later.
%%
%% This work has the LPPL maintenance status `maintained'.
%% 
%% The Current Maintainer of this work is the abnTeX2 team, led
%% by Lauro César Araujo. Further information are available on 
%% http://www.abntex.net.br/
%%
%% This work consists of the files abntex2-modelo-include-comandos.tex
%% and abntex2-modelo-img-marca.pdf
%%

% ---
% Este capítulo, utilizado por diferentes exemplos do abnTeX2, ilustra o uso de
% comandos do abnTeX2 e de LaTeX.
% ---

\externaldocument[I-]{chapter03}

\chapter{Empirical Evaluation}\label{ch:empirical_evaluation}

\iffalse
\chapterprecis{The purpose of this section is to present how our meta-reasoning is applied when solving \texttt{IPC} domain problens.}\index{sinopse de capítulo}
\fi


\texttt{RGHS} is guaranteed to find a near$-$optimal heuristic subset to guide the A$\sp{*}$ search granted that it is able to compute the objective function of interest. Thus, the practical effectiveness of \texttt{RGHS} depends on its ability of finding good approximations $\hat{J}$ and $\hat{T}$. Moreover, \texttt{RGHS}'s effectiveness depends on the value of $N$ and on the quality of the set of heuristics $\zeta$. In order to verify its practical effectivess, we have implemented \texttt{RGHS} in Fast Downward \cite{helmert2006fast} and tested the A$\sp{*}$ performance using subsets of heuristics selected by \texttt{RGHS} while minimizing different objective funcions.\\

We run two sets of experiments. In the first set we verify whether the approximations $\hat{J}$ and $\hat{T}$ provided by \texttt{CS} and \texttt{SS} allow \texttt{RGHS} to make near$-$optimal subset selections. In the second set of experiments we test the effectiveness of \texttt{RGHS} by measuring the total number of problem instances solved by A$\sp{*}$ using a heuristic subset selected by \texttt{RGHS}.\\

In our experiments we implemented an approximation procedure to automatically choose the subset size selected by \texttt{RGHS}, which we now explain. Initially we fix $N$ to a value (in our experiments we use $N = 25$). Then, in every iteration, when computing $M_{i}$, \texttt{RGHS} removes from $\zeta$ the heuristics that cannot help reducing $\varphi$. That is, in iteration $i$, all heuristics in $\zeta \backslash \zeta_{i-1}\sp{'}$ that cannot reduce $\varphi$ when combined with $\zeta_{i-1}\sp{'}$ are removed from $\zeta$. \texttt{RGHS} stops if $\zeta$ is empty and returns the current subset $\zeta\sp{'}$ with $|\zeta\sp{'}|<N$. Likewise, should heuristic $h$ improves the objective function being optimized, then we also allow \texttt{RGHS} to add $h$ to $\zeta\sp{'}$ even if $|\zeta\sp{'}| > N$. We observed in preliminary experiments that \texttt{RGHS} is robust to the initial value of $N$, as the total number of problems solved by A$\sp{*}$ while guided by a heuristic subset selected by \texttt{RGHS} varied little with $N$.\\

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
\centering
\caption{Ratios of the number of nodes expanded using $h_{max}(\zeta\sp{'})$ to the number of nodes expanded using $h_{max}(\zeta)$}
\begin{tabular}{lcccccc}
\hline
\multirow{2}{*}{Domain} & \multicolumn{2}{c}{\texttt{SS}} & \multicolumn{2}{c}{\texttt{CS}}   & \multirow{2}{*}{|$\zeta$|} & \multirow{2}{*}{n} \\ \cline{2-5}
                        & Ratio    & |$\zeta\sp{'}$|   & Ratio  & |$\zeta\sp{'}$| &                            &                    \\ \hline
Barman                  & 2.15     & 27.26       & 2.34   & 30.68           & 4790.16                    & 20                 \\
Elevators               & 1.09     & 18.00       & 1.04   & 20.00           & 155.00                     & 1                  \\
Floortile               & 1.01     & 45.86       & 1.01   & 41.14           & 136.57                     & 13                 \\
Openstacks              & 1.00     & 1.00        & 1.00   & 1.00            & 316.62                     & 12                 \\
Parking                 & 1.01     & 7.05        & 1.01   & 7.37            & 17.53                      & 18                 \\
Pegsol                  & 1.00     & 32.00       & 1.00   & 48.33           & 78.00                      & 2                  \\
Scanalyzer              & 1.01     & 37.29       & 1.07   & 21.43           & 52.14                      & 6                  \\
Tidybot                 & 1.03     & 4.06        & 1.00   & 8.19            & 3259.00                    & 15                 \\
Transport               & 7.33     & 9.70        & 1.45   & 12.90           & 156.50                     & 9                  \\
Visitall                & 1.00     & 95.00       & 1.02   & 48.00           & 218.00                     & 2                  \\
Woodworking             & 2.39     & 83.00       & 611.72 & 32.00           & 346.00                     & 5                  \\ \hline
\end{tabular}
\label{tb_one}
\end{table}

In all our experiments we use a type$-$system that assigned the same type for a node with the same $f-$value. Such a type system has shown to be effective in guiding \texttt{SS} to produce accurate tree size predictions in other application domains \cite{lelis2013predicting,lelis2014memory}.\\

We ran our experiments on the 2011 International Planning Competition (\texttt{IPC}) instances. We used the 2011 instances instead of the 2014 instances because the former do not have problems with conditional effects, which are currently not handled by \textbf{PDB} heuristics. All experiments are run on $2.67$ GHz machines with 4GB, and are limited to 1,800 seconds of running time.\\

% ---
\section{Empirical Evaluation of $\hat{J}$ and $\hat{T}$}
\noindent
% ---
We test whether the approximation $\hat{J}$ provided by \texttt{CS} and \texttt{SS} allows \texttt{RGHS} to make near$-$optimal subset selections. This test is made by comparing $J(\zeta\sp{'})$ with $J(\zeta)$, which is minimal. The condition $J(\zeta\sp{'}) \leq \alpha \cdot J(\zeta)$, is sufficient to show that $J(\zeta\sp{'})$ is within $\alpha$ times optimal with respect to all subsets of any size, for some constant $\alpha$. We are particularly interested in observing if $J(\zeta\sp{'})$ is within 1.36 of $J(\zeta)$.\\

In contrast with objective function $J$, there is no easy way to find the minimum of $T$ for a subset of fixed size in general. We experiment then with the special case in which all heuristics in $\zeta$ have the same evaluation time. This way we are able to test whether the estimates $\hat{T}$ are allowing \texttt{RGHS} to make near$-$optimal subset selections while minimizing the A$\sp{*}$ running time. This is because by only selecting heuristics which have the same evaluation time, if \texttt{RGHS} is making near$-$optimal subset selections with respect to $J$, then \texttt{RGHS} must also be making near$-$optimal subset selectioons with respect to $T$ for a fixed subset size (See Theorem \ref{th:theorem_two}).\\

We collect values of $J(\zeta)$ and $J(\zeta\sp{'})$ as follows. For each problem instance $\nabla$ in our test set we generate a set of \texttt{PDB} heuristics using the \texttt{GA-PDB} algorithm \cite{edelkamp2007automated} as described by \cite{BarleySantiagoOver} $-$ we call each \texttt{PDB} generated by this method a \texttt{GA-PDB}. We chose to use \texttt{GA-PDBs} in this experiment because they all have nearly the same evaluation time and will allow us to verify whether \texttt{RGHS} is making near$-$optimal selections not only when minimizing $J$ but also when minimizing $T$, as explained above. The number of \texttt{GA-PDBs} generated is limited in this experiment by 1,200 seconds and 1GB of memory. Also, all \texttt{GA-PDBs} we generate have 2 millions entries each. The \texttt{GA-PDBs} generated form out $\zeta$ set. \texttt{RGHS} then selects a subset $\zeta\sp{'}$ of $\zeta$. Finally, we use $h_{max}(\zeta\sp{'})$ and $h_{max}(\zeta)$ to independently try to solve $\nabla$. We call the system which uses A$\sp{*}$ with $h_{max}(\zeta)$ the \texttt{Max} approach. For \texttt{RGHS} we allow 600 seconds for selecting $\zeta\sp{'}$ and for running A$\sp{*}$ with $h_{max}(\zeta\sp{'})$, and for \texttt{Max} we allow 600 seconds for running A$\sp{*}$ with $h_{max}(\zeta)$. Since we used 1,200 seconds to generate the heuristics, both \texttt{Max} and \texttt{RGHS} were allowed 1,800 seconds in total for solving each problem. In this experiment we test both \texttt{CS} and \texttt{SS}.\\

In this experiment we refer to the approach that runs A$\sp{*}$ guided by a heuristic subset selected by \texttt{RGHS} using \texttt{CS} as \texttt{RGHS+CS}. Similarly, we write \texttt{RGHS+SS} when \texttt{SS} is used as predictor to make the heuristic subset selection.\\

Table \ref{tb_one} shows the average ratios of $J(\zeta\sp{'})$ to $J(\zeta)$ for both \texttt{SS} and \texttt{CS} in different problem domains. The value of $J$, for a given problem instance, is computed as the number of nodes expanded up to the largest $f-$layer which is fully expanded by all approaches tested (\texttt{Max, RGHS} using \texttt{SS} and \texttt{RGHS} using \texttt{CS}). We only present results for instances that are not solved during \texttt{RGHS}'s \texttt{CS} sampling process. The column $"n"$ shows the number of instances used to compute the averages of each row. We also show the average number of \texttt{GA-PDBs} generated (|$\zeta$|) and the average number of \texttt{GA-PDBs} selected by \texttt{RGHS} (|$\zeta\sp{'}$|). This experiment shows that for most of the problems \texttt{RGHS}, using either \texttt{CS} or \texttt{SS}, is selecting a near$-$optimal subset of $\zeta$. For example, in Tidybot \texttt{RGHS} selects only a few \texttt{GA-PDBs} out of thousands when using either \texttt{SS} or \texttt{CS}. Moreover, the resulting A$\sp{*}$ search tree size is on average at most 3$\%$ larger than optimal for \texttt{RGHS+SS}, and is optimal for \texttt{RGHS+CS}.\\

The exceptions in Table \ref{tb_one} are the ratios for Barman, Transport and Woodworking. In Transport \texttt{SS} has an average ratio of $7.33$ and \texttt{CS} of $1.45$. By looking at the ratios of \texttt{SS} for individual instances of \texttt{SS} for individual instances of Transport (results now show in Table \ref{tb_one}), we noticed that \texttt{SS} is able to make optimal selections for all but one of the 9 instances considered in this experiment. Since we do not know a priori what is the instance's optimal solution cost, \texttt{SS} samples nodes with $f-$values much larger than the instance's optimal solution cost. We believe that, in this particular instance of Transport, by sampling a portion of the state space that is not expanded during the actual A$\sp{*}$, \texttt{SS} is biasing the subset selection to select heuristics that do not contribute to reducing the actual A$\sp{*}$ search tree size.\\

The \texttt{SS}'s ability of sampling deep into the search space is not always harmful. For example, \texttt{SS} allows \texttt{RGHS} to make good selections for instances of the Woodworking domain. By contrast, \texttt{CS}'s systematic approach to sampling only allow a shallow sample of the A$\sp{*}$ search tree. As a result, \texttt{RGHS} makes a limited selection of heuristics to guide A$\sp{*}$ search. While \texttt{RGHS} using \texttt{SS} selects an average of 83 heuristics in Woodworking instances, \texttt{RGHS} using \texttt{CS} selects only an average of 32 heuristics. This difference on sampling strategies reflects on the number of problems solved by A$\sp{*}$. While \texttt{RGHS+SS} solves 15 instances of the Woodworking domain, \texttt{RGHS+CS} solves only 11. In total, out of the 280 instances of the \texttt{IPC} 2011 benchmark set, \texttt{RGHS+SS} solves 200 problem instances in this experiment, while \texttt{RGHS+CS} only solves 193 problem instances. (The numbers of instances solved are not shown in Table \ref{tb_one}).

\section{Comparison with Other Planning Systems}
\noindent
The objective of this second set of experiments is to teset the quality of the subset of heuristics \texttt{RGHS} selects while optimizing different objective functions. Our evaluation metric is coverage, \textsc{i.e.,} number of problems solved within a 1,800 second time limit. We note that the 1,800$-$second limit includes the time to generate $\zeta$, select $\zeta\sp{'}$, and run A$\sp{*}$ using $h_{max}(\zeta\sp{'})$. The $\zeta$ set of heuristics is composed of a number of different \texttt{GA-PDBs}, a \texttt{PDB} heuristic produced by the \texttt{iPDB} method \cite{haslum2007domain} and the \texttt{LM-Cut} heuristic. The generation of \texttt{GA-PDBs} is limited by 600 seconds and 1GB of memory. We use one fourth of 600 seconds to genetate \texttt{GA-PDBs} with each of the following number of entries: $\{2 \cdot 10\sp{3}, 2 \cdot 10\sp{4}, 2 \cdot 10\sp{5}, 2 \cdot 10\sp{6}\}$. Our approach allows one to generate up to thousands of \texttt{GA-PDBs}. For every problem instance, we use exactly the same $\zeta$ set for \texttt{Max} and all \texttt{RGHS} approaches.\\

\section{Systems Tested}
\noindent
\texttt{RGHS} is tested while minimizing the A$\sp{*}$ search tree size (\texttt{Size}) and the A$\sp{*}$ running time (\texttt{Time}). We also use \texttt{RGHS} to maximize the sum of heuristic values in the state space (\texttt{Sum}), as suggested by \cite{raynersss13}. \cite{raynersss13} assumed that one could uniformly sample states in the state space in order to estimte the sum of the heuristic values for a given heuristic subset. Since we are not aware of any method to uniformly sample the state space of domain$-$independent problems, we adapted the \cite{raynersss13}'s method by using \texttt{SS} to estimate the sum of heuristic values in the search tree rooted at $\nabla$'s start state. We write \texttt{Size + SS} to refer to the approach that used A$\sp{*}$ guided by a heuristic selected by \texttt{RGHS} while minimizing an estimate of the search tree size provided by \texttt{SS}. We follow the same pattern to name the other possible combinations of objective functions and prediction algorithms (\textsc{e.g.,}\texttt{Time+CS}).\\

In addition to experimenting with all combination of prediction algorithms (\texttt{CS} and \texttt{SS}) and objective functions (\texttt{Time}, \texttt{Size}), we also experiment with an approach that minimizes both the search tree size and the running time as follows. First we create a pool of heuristics $\zeta$ composed solely of \texttt{GA-PDB} heuristics, then we apply \texttt{RGHS} while minimizing tree size and using \texttt{SS} as predictor. As explained above, in this setting \texttt{RGHS} minimizes $J$ and $T$ simultaneaously, as all heuristics in $\zeta$ have the same evaluation time. We call the selection of a subset of \texttt{GA-PDBs} as the \textit{first selection}. Once the first selection is made, we test all possible combinations of the resulting $h_{max}(\zeta\sp{'})$ added to the \texttt{iPDB} and \texttt{LM-Cut} heuristics while minimizing the running time as estimated by \texttt{CS}$-$we call this step the \textit{second selection}. We call the overall approach \texttt{Hybrid}.\\

The intuition behind \texttt{Hibrid} is that we apply \texttt{RGHS} with its strongest settings, \textsc{i.e.,} according to Theorem \ref{th:theorem_two} \texttt{RGHS} makes selections that are within the 1.36 factor of optimal with respect to both $J$ and $T$ when selecting from a pool of heuristics with the same evaluation time. After such a selection is made, we reduce the size of the pool of heuristics from possible thousands to only tree (the maximum of a subset of the initial \texttt{GA-PDBs, iPDB}, and \texttt{LM-Cut}). With only three heuristics we are able to choose the exact combination that minimizes the A$\sp{*}$ running time the most. The reason we chose to use \texttt{SS} instead of \texttt{CS} for the first selection in \texttt{Hybrid} is that the former is able to make better subset selections in this setting, as suggested by the results discussed in the previous Chapter \ref{ch:rghs}. Finally, as we show below, \texttt{CS} is more effective if one is interested in minimizing the A$\sp{*}$ running time while selecting from a pool of heuristic with different evaluation times. That is why we use \texttt{CS} as predictor for the second selection in \texttt{Hybrid}.\\

We compare the coverage of the \texttt{RGHS} approaches with several other state$-$of$-$the$-$art planners. Namely, we experiment with RIDA$\sp{*}$ \cite{BarleySantiagoOver}, two variants of StoneSoup (StSp1 and StSp2) as described by \cite{nissim2011computing}, two versions of Symba (SY1 and SY2), and A$\sp{*}$ being independently guided by the maximum of all heuristics in $\zeta$ (\texttt{Max}), \texttt{iPDB, LM-cut} and \texttt{Merge $\&$ Shrink}(\texttt{M$\&$S}) \cite{nissim2011computing}.\\

The results are presented in Table \ref{tb_two}. The results for the \texttt{RGHS} approaches are averages computed over 10 independent runs of the planner; the average numbers are truncated to two decimal places in our table. The variance of the results is small, thus we omitted them from the table of results.\\

\section{Discussion of the Results}
\noindent
The system that solves the largest number of instances is \texttt{Hybrid}$-$ it solves 218.4 problems on average. As explained above, we combine in \texttt{Hybrid} the strengths of both \texttt{SS} and \texttt{CS} in a single system. \texttt{SS} is used to greedily select heuristics from a pool of heuristics with similar evaluation time, and only then \texttt{CS} is used for selecting heuristics with different evaluation times. This strategy has proven particularly effective on the Barman domain where \texttt{Hybrid}'s first selection is able to select good subsets of \texttt{GA-PDBs} and its second selection is able to recognize that it must not include the \texttt{iPDB} and \texttt{LM-Cut} heuristics to the subset selected by its first selection. As a result, \texttt{Hybrid} solves more problems on this domain than any other \texttt{RGHS} approach.\\

\texttt{Time+CS} also performed well in our experiments$-$the approach solves 215 problems on average. Clearly \texttt{Hybrid} and \texttt{Time+CS} are far superior to all other approaches tested. For example, \texttt{Size + SS} and \texttt{Sum} solves only 204 and 203 problems, respectively. While minimizing the search tree size or maximizing the sum of heuristic values, \texttt{RGHS} will tend to add accurate heuristics to the selected subset, independently of their evaluation time. As a result, if not minimizing the running time, \texttt{RGHS} often adds the \texttt{LM-Cut} heuristic to $\zeta\sp{'}$ as \texttt{LM-Cut} is often the heuristic that is able to reduce the most the search tree size and to increase the most the sum of heuristic values. However, \texttt{LM-Cut} is very computationally expensive, and in various cases the search is faster if \texttt{LM-Cut} is not in $\zeta\sp{'}$. Both \texttt{Hybrid} and \texttt{Time+CS} are able to recognize when \texttt{LM-Cut} should not be included in $\zeta\sp{'}$ because they account for the heuristics' evaluation time.\\

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[htb]
\footnotesize\setlength{\tabcolsep}{1.8pt}
\centering
\caption{Coverage of different planning systems on the 2011 \texttt{IPC} benchmarks. For the \texttt{RGHS} and \texttt{Max} approaches we also present the average number of heuristics \texttt{RGHS} selects (|$\zeta\sp{'}$|).}
\begin{tabular}{lccccccccccccccc}
\hline
\multirow{2}{*}{Domains} & \multirow{2}{*}{\texttt{Hybrid}} & \multicolumn{2}{c}{\texttt{CS}} & \multicolumn{2}{c}{\texttt{SS}} & \multirow{2}{*}{\texttt{Sum}} & \multirow{2}{*}{RIDA$\sp{*}$} & \multirow{2}{*}{SY1} & \multirow{2}{*}{SY2} & \multirow{2}{*}{StSp1} & \multirow{2}{*}{StSp2} & \multirow{2}{*}{\texttt{Max}} & \multirow{2}{*}{iPDB} & \multirow{2}{*}{LM-Cut} & \multirow{2}{*}{M$\&$S} \\ \cline{3-6}
                         &                                    & \texttt{Time} & \texttt{Size} & \texttt{Time} & \texttt{Size} &                                 &                       &                      &                      &                        &                        &                                 &                       &                         &                         \\ \hline
Barman                   & 6.9                                & 4.75            & 4               & 4               & 4               & 4                               & 4                     & 10                   & 11                   & 4                      & 4                      & 4                               & 4                     & 4                       & 4                       \\
Elevators                & 19                                 & 19              & 19              & 19              & 19              & 19                              & 19                    & 20                   & 20                   & 18                     & 18                     & 19                              & 17                    & 18                      & 12                      \\
Floortile                & 14                                 & 14              & 14              & 14              & 14              & 14                              & 14                    & 14                   & 14                   & 14                     & 14                     & 14                              & 8                     & 14                      & 10                      \\
Nomystery                & 20                                 & 20              & 20              & 20              & 20              & 19                              & 20                    & 16                   & 16                   & 20                     & 20                     & 20                              & 19                    & 14                      & 18                      \\
Openstacks               & 17                                 & 17              & 15              & 17              & 15              & 15                              & 15                    & 20                   & 20                   & 17                     & 17                     & 11                              & 17                    & 15                      & 17                      \\
Parcprinter              & 17.7                               & 18              & 19              & 15              & 16              & 16                              & 18                    & 17                   & 17                   & 18                     & 18                     & 18                              & 16                    & 17                      & 16                      \\
Parking                  & 7                                  & 7               & 1               & 2               & 2               & 2                               & 7                     & 2                    & 1                    & 5                      & 5                      & 2                               & 7                     & 2                       & 7                       \\
Pegsol                   & 19                                 & 19              & 19              & 19              & 19              & 19                              & 19                    & 19                   & 20                   & 19                     & 19                     & 19                              & 20                    & 17                      & 19                      \\
Scanalyzer               & 14                                 & 13.87           & 13              & 12              & 13              & 13                              & 14                    & 9                    & 9                    & 14                     & 14                     & 14                              & 10                    & 12                      & 11                      \\
Sokoban                  & 20                                 & 20              & 20              & 20              & 20              & 20                              & 20                    & 20                   & 20                   & 20                     & 20                     & 20                              & 20                    & 20                      & 20                      \\
Tidybot                  & 15.9                               & 16              & 16              & 16              & 16              & 16                              & 17                    & 15                   & 17                   & 16                     & 16                     & 15                              & 14                    & 16                      & 9                       \\
Transport                & 14                                 & 13.37           & 11              & 13              & 13              & 13                              & 10                    & 10                   & 11                   & 7                      & 8                      & 9                               & 8                     & 6                       & 7                       \\
Visitall                 & 18                                 & 18              & 17              & 17              & 17              & 17                              & 18                    & 12                   & 12                   & 16                     & 16                     & 18                              & 16                    & 10                      & 16                      \\
Woodworking              & 15.7                               & 15              & 15              & 12              & 16              & 16                              & 15                    & 20                   & 20                   & 15                     & 15                     & 16                              & 9                     & 15                      & 9                       \\ \hline
Total                    & 218.4                              & 215             & 203             & 200             & 204             & 203                             & 210                   & 204                  & 208                  & 203                    & 204                    & 199                             & 185                   & 180                     & 175                     \\ \hline
\end{tabular}
\label{tb_two}
\end{table}

Note tat the difference on the number of problems solved by \texttt{Time+CS} and \texttt{Time+SS}: While the former solves 215 instances, the latter solved only 200. We conjecture that this happens because \texttt{SS} is not able to detect duplicated nodes during sampling. As a result, \texttt{SS} often overestimates by several orders of magnitude the actual A$\sp{*}$'s running time. Similarly to the \texttt{Size} and \texttt{Sum} approaches, due to \texttt{SS}'s overestimations, \texttt{Time+SS} often mistakenly adds the accurate but expensive \texttt{LM-Cut} heuristic in cases where the A$\sp{*}$ search would be faster without \texttt{LM-Cut}'s guidence. For example, although \texttt{iPDB} tends to prune fewer nodes than \texttt{LM-Cut} in Parking instances, \texttt{iPDB} is the heuristic of choice in that domain. This is because its evaluation time is much smaller than \texttt{LM-Cut}'s. \texttt{Time+CS} solves 7 Parking instances on average as it correctly selects \texttt{iPDB} and leaves \texttt{LM-Cut} out of $\zeta\sp{'}$. By contrast, likely due to its prediction overestimation, \texttt{Time+SS} wrongly estimates that \texttt{LM-Cut} will reduce overall search time and adds the heuristic to its selected subset. Notice, that \texttt{Size+CS} and \texttt{Size+SS} also does poorly Parking instances as they also always select \texttt{LM-Cut}.\\

RIDA$\sp{*}$ is the most similar system to \texttt{RGHS}, as it also selects a subset of heuristics from a pool of heuristics by using an evaluation method similar to \texttt{CS}. RIDA$\sp{*}$ uses a systematic approach for selecting a subset of heuristics. Namely, it starts with an empty subset and evaluates all subsets of size $i$ before evaluating subsets of size $i+1$. This procedure allows RIDA$\sp{*}$ to consider only tens of heuristics in their pool. By contrast, \texttt{RGHS} is able to consider thousands of heuristics while making its selection.\\

The ability to handle large set of heuristics can be helpful, even if most of the heuristics in the set are redundant with each other.$-$as is the case with the \texttt{GA-PDBs}. The process of generating \texttt{GA-PDBs} is stochastic, thus one increases the chances of generating helpful heuristic by generating a large number of them. \texttt{RGHS} is an effective method for selecting a small set of informative heuristics from a large set of mostly uninformative ones. This is illustrated in Table \ref{tb_two} on the Transport domain. Compared to systems which use multiple heuristics (StSp1 and 2, and RIDA$\sp{*}$), \texttt{Time+CS} solves the largest number of Transport instances, which is due to the selection of a few key \texttt{GA-PDBs}.\\

The best \texttt{RGHS} approach, \texttt{Hybrid}, substantially outperforms the number of instances solved by \texttt{Max$-$Hybrid} solves on average more than 19 instances than \texttt{Max}. Finally, \texttt{Hybrid} and \texttt{Time+CS} substantially outperforms all other approaches tested, with RIDA$\sp{*}$ being the closest competitor with 210 instances solved.

\clearpage
