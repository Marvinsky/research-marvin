%% abtex2-modelo-include-comandos.tex, v-1.9.5 laurocesar
%% Copyright 2012-2015 by abnTeX2 group at http://www.abntex.net.br/ 
%%
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%   http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2005/12/01 or later.
%%
%% This work has the LPPL maintenance status `maintained'.
%% 
%% The Current Maintainer of this work is the abnTeX2 team, led
%% by Lauro César Araujo. Further information are available on 
%% http://www.abntex.net.br/
%%
%% This work consists of the files abntex2-modelo-include-comandos.tex
%% and abntex2-modelo-img-marca.pdf
%%

% ---
% Este capítulo, utilizado por diferentes exemplos do abnTeX2, ilustra o uso de
% comandos do abnTeX2 e de LaTeX.
% ---

%\chapter{Resultados de comandos}\label{cap_exemplos}
\chapter{About the Problem}\label{aboutTheProblem}

\iffalse
\chapterprecis{The purpose of this section if to motivate the problem.}\index{sinopse de capítulo}
\fi

State space search algorithms have been used to solve important real$-$world problems, such as: Robotics, domain-independent planning, chemical compounds discovery, bin packing, sequence alignment, automating layouts of sewers, and network routing, amount others. In this dissertation we study methods for selecting a subset of heuristic functions while minimizing the search tree size and the running time of search algorithm.\\

We are interested in selection of heuristics from a large set of heuristics because \cite{holte2006maximizing} showed that search can be faster if several smaller pattern databases are used instead of one large pattern database. In fact, we believe that each heuristic can give us valuable information about the solution of the problem. For example, one heuristic could be helpfull in some area of the search tree and other heuristics do not. Then, instead of using one heuristic to find the solution, would be the best to use the most promising heuristics from a large set of heuristics with the objective to find the solution of the problem.\\

\section{Problem Formulation}
\if false
\cite{lelis2013predicting} defines the search space and search tree in the following way: Let the \textit{underlying search tree} (\textit{UST}) be the full brute$-$force tree created from a connected, undirected and implicitely defined \textit{underlying search graph} (\textit{USG}) describing a state space. Some search algorithms expand a subtree of the \textit{UST} while searching for a solution (\textsf{e.g.,} a portion of the \textit{UST} might not be expanded due to heuristic guidance); they call this subtree the \textit{expanded search tree} \textit{(EST)}.\\

In this dissertation our methods require to estimate the size of the subgraph expanded by an algorithm searching the \textit{USG}; and the subgraph expanded recieve the name of expanded search graph \textit{ESG}.\\

Let $G = (N,E)$ be a graph representing an \textit{ESG} where $N$ is its set of states and for each $n \in N\  op(n) = {op_{i}|(n, n_i) \in E}$ is its set of operators. The term edges and operators are used interchangeably and work as a successor function which recieves as input a state and action and returns another state.\\
\fi

We use search algorithm to solve problems or find the solution knowing the sequence of actions that goes from the start state to the goal state. To solve the problem is required the use of search algorithms. Two well know search algorithms are Depth First Search (\texttt{DFS}) and Breadth First Search (\texttt{BFS}). \texttt{DFS} looks for the solution traversing the search space exploring the nodes in each branch before backtracking up to find the solution. \texttt{BFS} looks for the solution exploring the nodes in the first level, before moving to the next level of nodes. Both search algorithms have the characteristic that generate a larger search space during the search. The search space that these algorithms generate are called Brute force search tree (\texttt{BFST}).\\

There are other type of algorithms called heuristic search algorithms, which are algorithms that requires the use of heuristics. The heuristic is the estimation of the distance for one node in the search tree to get the goal state. The heuristic search algorithms generate smaller search tree in comparison to the \texttt{BFST}, because the heuristic guides the search to more promising parts of the state space or near to the objective. Also, by reducing the search tree size, the heuristic function guidance might also reduce the overall running time of the algorithm.

There are different approaches to create heuristics, such as: Pattern Databases (\texttt{PDBs}) \cite{haslum2007domain}, and Genetic Algorithm \cite{edelkamp2007automated}. We call these systems Heuristic Generators. And one of the approaches that have showed most successfull results in heuristic generation is the \texttt{PDBs}. The way how \texttt{PDBs} works is the following: The search space of the problem is abstracted, obtaining the remaining problem ``pattern‘’, which is small enough to be solved optimally by blind exhaustive search. The results are stored in a table which are the heuristic function for the original search space.\\

There exists many ways to take advantage of a large set of heuristic functions. For example: \cite{holte2006maximizing} showed that search can be faster if several smaller \texttt{PDBs} are used instead of one large pattern database. In addition \cite{domshlak2010max} and \cite{tolpin2013towards} showed that evaluating the heuristic lazily, only when they are essential to a decision to be made in the search process is worthy in comparison to take the maximum of the set of heuristics. Then, using all the heuristics do not guarantees to solve the major number of problems in a limit time.
% ---
\section{Aim and Objectives}
\subsection{Aim}
\noindent
The objective of this dissertation is to develop meta-reasoning approaches for selecting heuristics functions from a large set of heuristics with the goal of reducing the running time of the search algorithms employing these functions.

\subsection{Objectives}
\noindent

\begin{itemize}
  \item Demostrate that the problem of finding the optimal subset of heuristics $\zeta\sp{*}$ of size $N$ for a given problem task is supermodular respect the size of the search tree.
  
  \item Develop an approach to find a subset of heuristics from a large pool of heuristics $\zeta$ that optimize the number of nodes expanded in the process of search.
  
  \item Develop an approach for selecting a subset of heuristics functions based on the size of the search tree and running time.

  \item Compare \texttt{SS} algorithm for predicting the search tree size of Iterative-Deepening A* (IDA*).
  
  \item Use \texttt{SS} as our utility function.

\end{itemize}
% ---
\section{Scope, Limitations, and Delimitations}
\noindent
We implemented our method in Fast Downward \cite{helmert2006fast} and we test our methods on the 2011 International Planning Competition (\texttt{IPC}) domain instances.\\

\section{Justification}
\noindent
Domain-independent planning has obtained interesting results using heuristic search approach in problem solving. Using a proper heuristic to find the solution of the problem will represent in a reduction in the running time.\\

We use heuristic generators in order to create a large set of heuristics and obtain the most promosing heuristics to solve problems.\\

We believe that our idea of selecting heuristics using the size of the search tree and the running time will help us to solve more problems.

\section{Hypothesis}
\noindent
We test the following hypothesis:
\begin{itemize}
\item \textbf{H1:} Test that the greedy algorithms are effective for selecting a subset of heuristics to guide search.

\item \textbf{H2:} Test that \texttt{SS} is an effective prediction method to our meta-reasoning.
\end{itemize}

\section{Contribution of the Dissertation}
\noindent
The main contributions of this Dissertation are:
\begin{itemize}
\item Provide a meta-reasoning approach for selecting heuristic functions while minimizing the number of nodes expanded by the selecting heuristics.

\item Provide a meta-reasoning approach for selecting heuristic functions while minimizing the running time of the search. 
\end{itemize}

\section{Organization of the Dissertation}
\noindent
The Dissertation is organized as follows: 
\begin{enumerate}
\item In Chapter I, the background of the dissertation is provided. Which also includes our motivation and the scope definition.
\item In Chapter II, we review the state of the art in selection of heuristic functions.
\item In Chapter III, we introduce Random Greedy Heuristic Selection (\texttt{RGHS}) and the prediction methods. 
\item In Chapter IV, we explain the results obtained by using \texttt{RGHS} and compare it with other planner systems.
\item We conclude in Chapter V.
\end{enumerate}

In the next chapter, the domain 8$-$tile$-$puzzle is used to understand the concepts that will be helpful for the other chapters. \\

\clearpage