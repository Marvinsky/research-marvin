%Empieza configuracion
\setstretch{1.0}
\titleformat{\chapter}{\Huge\bfseries}{\thechapter}{0 pt}{\rule{340 pt}{3 pt}\\}
\titlespacing{\chapter}{100 pt}{-25 pt}{40 pt}[10 pt]	
\pagestyle{fancy}
\fancyhead[RO,RE]{\thepage}
\fancyfoot[CO,CE]{}
%Termina configuracion

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\setstretch{1.5} %Regresa el interlineado a 1.5


\normalsize
\noindent
In this dissertation we present a greedy method based on the theory of supermodular optimization for selecting a subset of heuristics functions from a large set of heuristics with the objective of reducing the running time of the search algorithms. \\ 

 \cite{holte2006maximizing} showed that search can be faster if several smaller pattern databases are used instead of one large pattern database. We introduce a greedy method for selecting a subset of the most promising heuristicss from a large set of heuristics functions to guide the A* search algorithm. If the heuristics are consistent, our method selects a subset which is guaranteed to be near optimal with respect to the resulting A* search tree size. In addition to being consistent, if all heuristics have the same evaluation time, our subset is guaranteed to be near optimal with respect to the resulting A* running time. We implemented our method in Fast Downward and showed empirically that it produces heuristics which outperform the state of the art heuristics in the International Planning Competition benchmarks.

\clearpage