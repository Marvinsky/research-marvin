reading input... [t=0.00s]
Simplifying transitions... done!
done reading input! [t=0.00s]
building causal graph...done! [t=0.00s]
packing state variables...done! [t=0.00s]
Variables: 9
Facts: 61
Bytes per state: 4
done initalizing global data [t=0.00s]
args[12]:ss(min([gapdb(mp=0.5), automate_GAs]))
input arg:ss(min([gapdb(mp=0.5), automate_GAs]))
new arg after erase:ss(min([gapdb(mp=0.5), 
calling ScalarEvaluator Min parser
args[12]:ss(min([gapdb(mp=0.5), automate_GAs]))
input arg:ss(min([gapdb(mp=0.5), automate_GAs]))
new arg after erase:ss(min([gapdb(mp=0.5), 
calling ScalarEvaluator Min parser
use_saved_pdbs = 1
No patterns stored,calling load_GA_Patterns_from_file
problem_name_mod = dat/elevators-opt08-strips/p01.dat
Calling load_GA_Patterns_from_file
log_file:dat/elevators-opt08-strips/p01.dat,g_plan_filename:sas_plan
is_open true
problem_found among stored GAs:sas_plan
stored_GA_patterns.size:1,time:0.00
,problem_name_mod:sas_plan:
disjoint_patterns:,0
mutation_rate_string:mp:,0.5000000,
pdb_max_size_string:size:,50000,
line:sas_plan:returning best heuristic(GAPDB)[,0,]:[1,4,5,6,8]-[0,2,6,7,8]-,mp:,0.5000000,size:,50000,disjoint_patterns:,0-best_fitness:24.9465,,initial value:29,GAPDB generation time:0.08
use_saved_pdbs = 1
,problem_name_mod:sas_plan:
disjoint_patterns:,1
mutation_rate_string:mp:,0.6000000,
pdb_max_size_string:size:,20000,
No Name,set_stop_using=true
use_saved_pdbs = 1
,problem_name_mod:sas_plan:
disjoint_patterns:,1
mutation_rate_string:mp:,1.0000000,
pdb_max_size_string:size:,20000,
No Name,set_stop_using=true
use_saved_pdbs = 1
,problem_name_mod:sas_plan:
disjoint_patterns:,0
mutation_rate_string:mp:,0.8000000,
pdb_max_size_string:size:,20000,
No Name,set_stop_using=true
use_saved_pdbs = 1
,problem_name_mod:sas_plan:
disjoint_patterns:,0
mutation_rate_string:mp:,0.2000000,
pdb_max_size_string:size:,20000,
No Name,set_stop_using=true
use_saved_pdbs = 1
,problem_name_mod:sas_plan:
disjoint_patterns:,0
mutation_rate_string:mp:,0.4000000,
pdb_max_size_string:size:,20000,
No Name,set_stop_using=true
returning MinEvaluator
SSSearch ...
cleared store_GA_patterns.

totalPrediction : 1649915659.90
ss_timer: 2.28
probes: 1000
threshold : 42.00
count nodes generates : 23704808134.35
count nodes expanded : 1649915659.90
dominio = elevators-opt08-strips
tarefa = p01.pddl
heuristica = gapdb
Directory: gapdb created.
Directory: fdist created.
print.
g:0
size: 1
	f: 0	q: 1.00

g:1
size: 7
	f: 6	q: 3.17
	f: 7	q: 3.84
	f: 8	q: 1.13
	f: 9	q: 1.02
	f: 13	q: 0.89
	f: 19	q: 1.01
	f: 25	q: 0.95

g:2
size: 24
	f: 6	q: 3.88
	f: 7	q: 5.23
	f: 8	q: 1.09
	f: 9	q: 0.62
	f: 12	q: 10.76
	f: 13	q: 20.57
	f: 14	q: 26.05
	f: 15	q: 14.82
	f: 16	q: 11.54
	f: 17	q: 0.94
	f: 18	q: 1.09
	f: 19	q: 6.86
	f: 20	q: 7.02
	f: 21	q: 1.40
	f: 22	q: 2.03
	f: 25	q: 7.02
	f: 26	q: 11.86
	f: 27	q: 2.34
	f: 28	q: 1.25
	f: 31	q: 4.56
	f: 32	q: 8.14
	f: 33	q: 1.46
	f: 34	q: 2.17
	f: 38	q: 1.39

g:3
size: 32
	f: 6	q: 2.03
	f: 7	q: 5.94
	f: 9	q: 2.03
	f: 12	q: 23.68
	f: 13	q: 69.05
	f: 14	q: 34.48
	f: 15	q: 32.57
	f: 16	q: 24.53
	f: 18	q: 41.82
	f: 19	q: 91.07
	f: 20	q: 214.34
	f: 21	q: 183.83
	f: 22	q: 134.44
	f: 23	q: 91.10
	f: 24	q: 37.79
	f: 25	q: 55.56
	f: 26	q: 98.47
	f: 27	q: 78.91
	f: 28	q: 43.01
	f: 29	q: 26.80
	f: 31	q: 39.35
	f: 32	q: 113.52
	f: 33	q: 112.30
	f: 34	q: 61.38
	f: 35	q: 34.78
	f: 36	q: 10.26
	f: 37	q: 24.68
	f: 38	q: 66.90
	f: 39	q: 80.35
	f: 40	q: 39.37
	f: 41	q: 30.65
	f: 42	q: 4.40

g:4
size: 30
	f: 12	q: 24.48
	f: 13	q: 28.51
	f: 14	q: 150.20
	f: 15	q: 95.86
	f: 16	q: 46.93
	f: 18	q: 151.40
	f: 19	q: 236.83
	f: 20	q: 459.80
	f: 21	q: 619.70
	f: 22	q: 528.82
	f: 23	q: 276.73
	f: 24	q: 194.75
	f: 25	q: 368.60
	f: 26	q: 1642.04
	f: 27	q: 1628.94
	f: 28	q: 1970.83
	f: 29	q: 878.98
	f: 30	q: 937.06
	f: 31	q: 735.46
	f: 32	q: 1059.38
	f: 33	q: 800.74
	f: 34	q: 1378.24
	f: 35	q: 504.35
	f: 36	q: 264.04
	f: 37	q: 382.98
	f: 38	q: 811.66
	f: 39	q: 1113.19
	f: 40	q: 1223.71
	f: 41	q: 924.84
	f: 42	q: 587.18

g:5
size: 26
	f: 16	q: 344.15
	f: 18	q: 346.32
	f: 19	q: 58.03
	f: 20	q: 2074.90
	f: 21	q: 2299.20
	f: 22	q: 895.58
	f: 23	q: 334.82
	f: 24	q: 409.67
	f: 25	q: 1607.82
	f: 26	q: 2499.55
	f: 27	q: 8056.79
	f: 28	q: 4650.07
	f: 29	q: 7599.58
	f: 30	q: 3908.78
	f: 31	q: 3787.94
	f: 32	q: 6870.61
	f: 33	q: 12390.34
	f: 34	q: 16783.56
	f: 35	q: 15166.10
	f: 36	q: 11988.18
	f: 37	q: 10166.17
	f: 38	q: 9957.24
	f: 39	q: 16130.22
	f: 40	q: 11318.18
	f: 41	q: 10642.96
	f: 42	q: 10874.30

g:6
size: 23
	f: 19	q: 3475.01
	f: 20	q: 97.34
	f: 21	q: 5160.53
	f: 22	q: 4784.53
	f: 23	q: 7028.86
	f: 25	q: 4171.10
	f: 26	q: 8975.56
	f: 27	q: 24804.86
	f: 28	q: 23472.24
	f: 29	q: 26290.86
	f: 30	q: 7760.44
	f: 31	q: 7728.43
	f: 32	q: 26994.97
	f: 33	q: 43987.16
	f: 34	q: 80225.74
	f: 35	q: 72029.21
	f: 36	q: 75035.53
	f: 37	q: 39210.53
	f: 38	q: 72205.61
	f: 39	q: 92356.78
	f: 40	q: 142214.17
	f: 41	q: 145247.08
	f: 42	q: 155335.24

g:7
size: 17
	f: 24	q: 314.35
	f: 27	q: 51637.10
	f: 28	q: 136432.92
	f: 29	q: 72146.32
	f: 30	q: 104205.55
	f: 31	q: 4026.84
	f: 32	q: 159370.19
	f: 33	q: 260569.30
	f: 34	q: 281160.94
	f: 35	q: 292193.95
	f: 36	q: 229511.32
	f: 37	q: 239578.19
	f: 38	q: 207175.32
	f: 39	q: 257106.80
	f: 40	q: 766969.01
	f: 41	q: 788665.64
	f: 42	q: 895891.19

g:8
size: 15
	f: 27	q: 48383.71
	f: 28	q: 329.47
	f: 30	q: 226.51
	f: 31	q: 2937.60
	f: 32	q: 124253.42
	f: 33	q: 618136.13
	f: 34	q: 1005190.27
	f: 35	q: 295962.38
	f: 36	q: 1017038.15
	f: 37	q: 1249685.56
	f: 38	q: 1096212.29
	f: 39	q: 2308463.96
	f: 40	q: 2815724.93
	f: 41	q: 4232692.57
	f: 42	q: 5190660.71

g:9
size: 12
	f: 31	q: 2244.53
	f: 32	q: 3343.96
	f: 33	q: 1591349.09
	f: 34	q: 7126.85
	f: 35	q: 1991962.06
	f: 36	q: 5054307.17
	f: 37	q: 828560.75
	f: 38	q: 1250856.85
	f: 39	q: 2924288.33
	f: 40	q: 12569116.33
	f: 41	q: 5471307.61
	f: 42	q: 18814124.70

g:10
size: 9
	f: 34	q: 43804.80
	f: 35	q: 628570.37
	f: 36	q: 1013412.10
	f: 37	q: 499029.79
	f: 38	q: 3290609.95
	f: 39	q: 11616807.77
	f: 40	q: 35477573.40
	f: 41	q: 25029214.73
	f: 42	q: 56029756.93

g:11
size: 9
	f: 33	q: 1693201.54
	f: 35	q: 110246.40
	f: 36	q: 38218.75
	f: 37	q: 79483.39
	f: 38	q: 595902.91
	f: 39	q: 23345050.37
	f: 40	q: 48415762.32
	f: 41	q: 43761736.61
	f: 42	q: 98744430.16

g:12
size: 6
	f: 37	q: 160175.88
	f: 38	q: 1380789.10
	f: 39	q: 22381945.20
	f: 40	q: 39258124.13
	f: 41	q: 99103769.66
	f: 42	q: 74399639.60

g:13
size: 5
	f: 38	q: 44890.56
	f: 39	q: 19127130.05
	f: 40	q: 3609996.34
	f: 41	q: 10193844.10
	f: 42	q: 149752658.76

g:14
size: 3
	f: 39	q: 85051.30
	f: 41	q: 138913266.82
	f: 42	q: 22774146.77

g:15
size: 2
	f: 40	q: 228582207.36
	f: 42	q: 1763942.40

g:16
size: 1
	f: 39	q: 228582207.36

g:17
size: 1
	f: 42	q: 137149324.42

g:18
size: 1
	f: 39	q: 45716441.47

g:19
size: 0

g:20
size: 0

g:21
size: 0

g:22
size: 0

g:23
size: 0

g:24
size: 0

g:25
size: 0

g:26
size: 0

g:27
size: 0

g:28
size: 0

g:29
size: 0

g:30
size: 0

g:31
size: 0

g:32
size: 0

g:33
size: 0

g:34
size: 0

g:35
size: 0

g:36
size: 0

g:37
size: 0

g:38
size: 0

g:39
size: 0

g:40
size: 0

g:41
size: 0

g:42
size: 0

Actual search time: 2.28s [t=2.30s]
Search time: 2.28s
Total time: 2.30s
Search stopped without finding a solution.
Peak memory: 4228 KB
